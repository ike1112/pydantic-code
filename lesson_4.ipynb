{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301bb46e",
   "metadata": {},
   "source": "# Direct API Integration: Using Pydantic Schemas with LLM Providers\n\nThis notebook demonstrates using Pydantic models directly in API calls to various LLM providers to receive structured output. Instead of manually implementing retry mechanisms, modern frameworks can handle validation automatically when you pass Pydantic models directly to the API.\n\nKey concepts demonstrated:\n- Use Pydantic models directly in LLM API calls\n- Receive properly structured responses using different frameworks and providers\n- Compare approaches across OpenAI, Anthropic, and other providers\n\n---\n\n### Import libraries and set up environment"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b11c5e5",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3eab72",
   "metadata": {},
   "source": "### Define Pydantic models for user input and LLM output"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c21e83",
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "# Define the UserInput model for customer support queries\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None\n",
    "\n",
    "# Define the CustomerQuery model that inherits from UserInput\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4d86b",
   "metadata": {},
   "source": "### Sample input data and model validation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ded7c6",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": "# Define input data as a JSON string\nuser_input_json = '''{\n    \"name\": \"Joe User\",\n    \"email\": \"joe.user@example.com\",\n    \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n    \"order_number\": 12345,\n    \"purchase_date\": \"2025-12-31\"\n}'''"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1bc95",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": "# Validate the input data by creating a UserInput instance\nuser_input = UserInput.model_validate_json(user_input_json)"
  },
  {
   "cell_type": "markdown",
   "id": "04b48355",
   "metadata": {},
   "source": "### Anthropic API with Instructor for structured output"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7505cb71",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"Analyze the following customer query {user_input} \"\n",
    "    f\"and provide a structured response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363746c",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": "# Load environment variables\nload_dotenv()\n# Use Anthropic with Instructor to get structured output\nanthropic_client = instructor.from_anthropic(\n    anthropic.Anthropic()\n)\n\nresponse = anthropic_client.messages.create(\n    model=\"claude-3-7-sonnet-latest\",  \n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": prompt\n        }\n    ],\n    response_model=CustomerQuery  \n)"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ea2ec7",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CustomerQuery'>\n",
      "{\n",
      "  \"name\": \"Joe User\",\n",
      "  \"email\": \"joe.user@example.com\",\n",
      "  \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n",
      "  \"order_id\": null,\n",
      "  \"purchase_date\": \"2025-12-31\",\n",
      "  \"priority\": \"high\",\n",
      "  \"category\": \"refund_request\",\n",
      "  \"is_complaint\": true,\n",
      "  \"tags\": [\n",
      "    \"damaged product\",\n",
      "    \"monitor\",\n",
      "    \"replacement\",\n",
      "    \"repeated issue\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the returned structured data\n",
    "print(type(response))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a39682",
   "metadata": {},
   "source": "### OpenAI's structured output API with Pydantic schema"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d342f4a",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": "# Initialize OpenAI client and call with CustomerQuery schema\nopenai_client = OpenAI()\nresponse = openai_client.beta.chat.completions.parse(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    response_format=CustomerQuery\n)\nresponse_content = response.choices[0].message.content\nprint(type(response_content))\nprint(response_content)"
  },
  {
   "cell_type": "markdown",
   "id": "257c716e",
   "metadata": {},
   "source": "### Advanced usage examples and API exploration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0facf3a",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": "# Validate the response from the LLM\nvalid_data = CustomerQuery.model_validate_json(\n    response_content\n)\nprint(type(valid_data))\nprint(valid_data.model_dump_json(indent=2))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6a29f",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": "# Test the responses API from OpenAI\nresponse = openai_client.responses.parse(\n    model=\"gpt-4o\",\n    input=[{\"role\": \"user\", \"content\": prompt}],\n    text_format=CustomerQuery\n)\n\nprint(type(response))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38913864",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": "# Explore class inheritance structure of the OpenAI response\ndef print_class_inheritence(llm_response):\n    for cls in type(llm_response).mro():\n        print(f\"{cls.__module__}.{cls.__name__}\")\n\nprint_class_inheritence(response)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92138d5",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": "# Display the response type and content \nprint(type(response.output_parsed))\nprint(response.output_parsed.model_dump_json(indent=2))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb392c18",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": "# Test the Pydantic AI package for agent-based structured responses\nfrom pydantic_ai import Agent\nimport nest_asyncio\nnest_asyncio.apply()\n\nagent = Agent(\n    model=\"google-gla:gemini-2.0-flash\",\n    output_type=CustomerQuery,\n)\n\nresponse = agent.run_sync(prompt)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54073bc3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": "# Display the response type and content\nprint(type(response.output))\nprint(response.output.model_dump_json(indent=2))"
  },
  {
   "cell_type": "markdown",
   "id": "76c4a537",
   "metadata": {},
   "source": "---\n\n## Summary\n\nThis notebook demonstrates how to use Pydantic models to extract structured, validated output directly from LLMs using various API providers including OpenAI and Anthropic. By defining expected output schemas with Pydantic and passing them directly to API calls, you can eliminate manual parsing and validation code while receiving reliable, well-formed responses in a single API call. This approach enables focus on designing clear data models and prompts, making code more maintainable and robust."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}